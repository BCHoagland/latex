\documentclass[twoside,10pt]{report}
\usepackage{/Users/bradenhoagland/latex/breaks}
%\toggletrue{sectionbreaks}
\newcommand{\docTitle}{Random Betti Numbers}
\usepackage{/Users/bradenhoagland/latex/math2}

%\renewcommand{\theenumi}{\alph{enumi}}

\begin{document}
%\tableofcontents

%%%%%%%%%%%%%%%%%%%%
% Notation
%%%%%%%%%%%%%%%%%%%%

\section{Notation}

Any probability $p$ is implicitly a function of $n$, so keep this in mind when taking limits as $n\to \infty$. You can't just treat $p$ like a constant.

The $O,\Omega,\Theta,o,\omega$ notation is all standard. If
\[
\lim_{n \to \infty} \frac{A_{n}}{B_{n}} =1
\] then we say $A_{n} \approx B_{n}$. We abuse notation a bit by saying $A_{n} \leq B_{n}$ if there is some constant $c$ such that $A_{n} \leq c B_{n}$ for all $n$.

We say that $A_n$ converges weakly to $A$ if
\[
	\lim_{n \to \infty} \mathbb{E}\left[ f(A_{n}) \right]=\mathbb{E}\left[ f(A) \right]
\] for all bounded continuous functions $f$. We denote this by $A_{n}\Rightarrow A$. {\color{red}(definition in terms of CDFs instead?)}

%%%%%%%%%%%%%%%%%%%%
% Erd\"os-R\'enyi Random Clique Complexes
%%%%%%%%%%%%%%%%%%%%

\section{Erd\"os-R\'enyi Random Clique Complexes}

\begin{imp}
In the Erd\"os-R\'enyi clique complex, if $p$ is in a certain regime, each expected Betti number will be nonzero with high probability. In addition, each Betti number will satisfy a central limit theorem.
\end{imp}

\begin{note}[]
Throughout this section, assume $p$ is in the following regime:
\begin{align*}
	p&=\omega(n^{-1/k}),\\
	p&=o(n^{-1/(k+1)}).
\end{align*}
\end{note}

\begin{lem}[Morse Inequalities]
	Let $f_{k}$ denote the number of $k$-dimensional faces of a simplicial complex $\Delta$, and let $\beta_{k}$ denote the $k$-th Betti number of $\Delta$. Then
	\[
	-f_{k-1}+f_{k}-f_{k+1} \leq \beta_{k} \leq f_{k}.
	\] 
\end{lem}
\begin{proof}
	{\color{red}Do this. Uses definition of simplicial homology and the rank nullity theorem.}
\end{proof}

%%%%%%%%%%
\newpage
%%%%%%%%%%

\begin{thrm}[]
	$\beta_{k}$ is nonzero with high probability. Explicitly,
\[
	\lim_{n \to \infty} \frac{\mathbb{E}[\beta_{k}]}{n^{k+1}p^{\binom{k+1}{2}}} = \frac{1}{(k+1)!} .
\] 
\end{thrm}
\begin{proof}
	The desired limit relation is actually straightforward to show for $f_{k}$ instead of $\beta_{k}$. So we'll do that, then use our assumptions on $p$ and the Morse inequalities to show that $\beta_{k}$ has the same property.

	Note that $f_{k}$ also represents the number of $(k+1)$-cliques of our complex. Since the complex is Erd\"os-R\'enyi, each of the $\binom{n}{k+1}$ possible $(k+1)$-cliques occur with the same probability. Since a $(k+1)$-clique has $\binom{k+1}{2}$ distinct edges, this probability is $p^{\binom{k+1}{2}}$.

	But $f_k$ is really just the sum of $\binom{n}{k+1}$ indicator functions, each tracking whether or not a particular $(k+1)$-clique is present in the complex. Since each clique has equal probability of forming, this means the expectation of $f_{k}$ is
	\[
		\mathbb{E}[f_{k}] = \binom{n}{k+1}p^{\binom{k+1}{2}} = \frac{n!}{(n-k-1)!(k+1)!} p^{\binom{k+1}{2}}.
	\] The limit of our desired quantity, but with $f_{k}$ substituted in place of $\beta_{k}$, is then
	\[
		\lim_{n \to \infty} \frac{\mathbb{E}[f_{k}]}{n^{k+1}p^{\binom{k+1}{2}}} = \lim_{n \to \infty} \frac{n \cdots (n-k)}{n^{k+1}(k+1)!} = \frac{1}{(k+1)!}.
	\] 
	We can then use our assumption on the regime of $p$ and the Morse inequalities to show that $\beta_{k}$ has the same property. Since $p = \omega(n^{-1/k})$,
	\[
		\lim_{n \to \infty} \frac{\mathbb{E}[f_{k-1}]}{\mathbb{E}[f_k]} = \lim_{n \to \infty} \frac{k+1}{n p^{k}} = 0.
	\] And since $p= o(n^{-1/(k+1)})$, we similarly have $\lim_{n \to \infty} \mathbb{E}\left[ f_{k+1} \right] / \mathbb{E}\left[ f_{k} \right] =0$. Thus in this regime of $p$,
	\[
	\lim_{n \to \infty} \frac{\mathbb{E}\left[ -f_{k-1}+f_{k}-f_{k+1} \right]}{\mathbb{E}\left[ f_{k} \right]}=1.
	\] 
	Then by the Morse inqualities, $\beta_{k}$ must satisfy the desired limit property.
\end{proof}

\begin{cor}
\label{cor:morse-exp}
As $n\to \infty$,
\[
\mathbb{E}\left[ -f_{k-1}+f_{k}-f_{k+1} \right] = \mathbb{E}\left[ \beta_{k} \right] = \mathbb{E}\left[ f_{k} \right].
\] 
\end{cor}
\begin{proof}
	This follows from the last equation of the previous proof.
\end{proof}



Now we know that $\beta_{k}$ is very likely nonzero (at least in our specific regime of $p$). Since it's not just some trivial quantity, a central limit theorem for it is a meaningful statement.

To do so, we'll use the Morse inequalities again. Proving central limit theorems for the non-$\beta_{k}$ terms in the inequalities is easier, and we can use them to get the desired property for $\beta_{k}$ itself. To clean up notation, let $g_{k} \doteq -f_{k-1}+f_{k}-f_{k+1}$.

\begin{lem}
\label{lem:var}
As $n\to \infty$,
\[
	\lim_{n \to \infty} \frac{\var(f_{k})}{\var(g_{k})} =1.
\] 
\end{lem}
\begin{proof}
	{\color{red}Do this.}
\end{proof}

\begin{cor}
\label{cor:var}
As $n\to \infty$,
\[
	\var(g_{k}) = \var(\beta_{k}) = \var(f_{k}).
\]
\end{cor}

\begin{lem}
\label{lem:fk-ctl}
$f_{k}$ obeys a central limit theorem, i.e. as $n\to \infty$,
\[
	\frac{f_{k}- \mathbb{E}\left[ f_{k} \right]}{\sqrt{\var(f_{k})} } \Rightarrow \mathcal{N}(0,1).
\] 
\end{lem}
\begin{proof}
	{\color{red}Do this}.
\end{proof}

\begin{lem}
\label{lem:gk-ctl}
$g_{k}$ obeys a central limit theorem, i.e. as $n\to \infty$,
\[
        \frac{g_{k}- \mathbb{E}\left[ g_{k} \right]}{\sqrt{\var(g_{k})} } \Rightarrow \mathcal{N}(0,1).
\]
\end{lem}
\begin{proof}
        {\color{red}Do this}.
\end{proof}

\begin{thrm}[]
	Suppose $p=\omega(n^{-1/k})$ and $p=o(n^{-1/(k+1)})$, then
\[
	\frac{\beta_{k}- \mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \Rightarrow \mathcal{N}(0,1).
\] 
\end{thrm}
\begin{proof}
	{\color{red}I'm 99\% sure that this has some serious logical errors. I don't think you can just move a limit inside of a probability, but that's what I'm doing I think. The original paper authors don't really explain what they did, though, so I'm confused. They say that the theorem has been proven once they have
	\[
		\Phi(t) \leq \mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ f_{k} \right]}{\sqrt{\var(f_{k})} }  \right) \leq \Phi(t + \varepsilon)
	\] for arbitrary $\varepsilon$, but this isn't really what we're trying to prove. If we can move limits inside the probabilities, though, then our earlier corollaries give us the result. But if we can do that, then why didn't they do what I do below? It seems a lot simpler.}
	Since $\beta_{k} \leq f_{k}$,
	\[
		\mathbb{P}\left( \frac{f_{k}-\mathbb{E}\left[ f_{k} \right]}{\sqrt{\var(f_{k})} } \leq t \right)  \leq \mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ f_{k} \right]}{\sqrt{\var(f_{k})} } \leq t \right).
	\] 
	Now let $n\to \infty$. By Lemma \ref{lem:fk-ctl}, this becomes
	\[
		\Phi(t) \leq \mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ f_{k} \right]}{\sqrt{\var(f_{k})} } \leq t \right).
	\] By Corollaries \ref{cor:morse-exp} and \ref{cor:var}, we get $\mathbb{E}\left[ \beta_{k} \right]=\mathbb{E}\left[ f_{k} \right]$ and $\var(f_{k}) = \var(\beta_{k})$ in the limit. Thus as $n\to \infty$,
	\[
		\Phi(t) \leq \mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \leq t \right),
	\] 
	so the CDF of $\beta_{k}$ is bounded below by the CDF of the standard normal distribution. Similarly, since $g_{k} \leq \beta_{k}$,
	\[
		\mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \leq t \right) \leq \mathbb{P}\left( \frac{g_{k}-\mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \leq t \right).
	\] Letting $n\to \infty$ and applying Corollaries \ref{cor:morse-exp} and \ref{cor:var} and Lemma \ref{lem:gk-ctl}, this becomes
	\[
		\mathbb{P}\left( \frac{\beta_{k}-\mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \leq t \right) \leq \Phi(t).
	\] Since the lower and upper bounds are both $\Phi(t)$, we conclude
	\[
		\frac{\beta_{k}-\mathbb{E}\left[ \beta_{k} \right]}{\sqrt{\var(\beta_{k})} } \Rightarrow \mathcal{N}(0,1),
	\] as desired.
\end{proof}

\end{document}
